---
layout: default
title: Mozilla Foundation on Trustworthy AI
nav_order: 30
parent: Exploring AI Trust and Safety
---

# Mozilla Foundation on Trustworthy AI

In theory, the principals we have discussed so far could be applied to closed or open AI systems. The Mozilla Foundationâ€™s [Accelerating Progress Toward Trustworthy AI](https://foundation.mozilla.org/en/research/library/accelerating-progress-toward-trustworthy-ai/whitepaper/){:target="_mozilla"} strongly advocates for open source as the basis for successful and safe AI innovation and application, just as open source proved to be the best way to make software itself secure. This document is an accessible introduction to AI trustworthiness, including safety, but also accountability and user agency.

Openness promotes faster innovation and easier accountability, such as quick detection and resolution of bugs, vulnerabilities, etc. It promotes greater agency for users of AI. It makes it easier to ensure that AI is generally beneficial to society and individuals, rather than detrimental. If control of AI were limited to a few, well-capitalized institutions, all these desirable outcomes would be difficult to achieve.

Openness also involves diversity of voices to minimize biases against particular demographic groups, cultures, and countries. Technologies need to improve for detecting and mitigating bias and other undesirable outputs. Not everyone has access to enormous compute resources, so efforts to build small models that perform well while running on devices like laptops are essential for broadening the community. Effective use of AI also requires an informed public, so efforts to train consumers and workers, as well as developers, are crucial.

The next section dives into the [MLCommons Taxonomy of Hazards]({{site.baseurl}}/exploring/mlcommons-taxonomy-hazards).
